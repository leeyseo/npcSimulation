# memory_manager.py
import datetime
import json
import os
import numpy as np
from collections import defaultdict, deque
from data_structures import Memory, Knowledge
from config import (
    SHORT_TERM_MAXLEN, SUMMARY_WINDOW, MEMORY_DIR,
    SHORT_TERM_FILE, LONG_TERM_FILE, SCORE_WEIGHTS, RECENCY_DECAY
)


class MemoryManager:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, llm_utils, name: str, persona_desc: str = ""):
        self.llm_utils = llm_utils
        self.name = name
        self.persona_description = persona_desc

        # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
        self.seq_event = []
        self.seq_thought = []
        self.kw_to_event = defaultdict(list)
        self.kw_to_thought = defaultdict(list)
        self.kw_strength = defaultdict(int)

        # ì§€ì‹ ë² ì´ìŠ¤
        self.knowledge_base: dict[str, Knowledge] = {}

        # ë©”ëª¨ë¦¬ ë£¸
        self.memory_dir = MEMORY_DIR
        os.makedirs(self.memory_dir, exist_ok=True)
        self.short_term_path = os.path.join(self.memory_dir, SHORT_TERM_FILE)
        self.long_term_path = os.path.join(self.memory_dir, LONG_TERM_FILE)

        self.short_term_memory_room = deque(maxlen=SHORT_TERM_MAXLEN)
        self.long_term_memory_room = []
        
        # â–¼ [ì¶”ê°€ 1] JSON â†’ ë©”ëª¨ë¦¬ ë³µì›
        self._load_memory_rooms()

        # â–¼ [ì¶”ê°€ 2] íŒŒì¼ì— ì•„ë¬´ê²ƒë„ ì—†ì„ ë•Œë§Œ ê¸°ë³¸ ê¸°ì–µ ìƒì„±
        if not self.short_term_memory_room and not self.long_term_memory_room:
            self.add_memory('event', f"ë‚˜ì˜ ì´ë¦„ì€ '{name}'ì´ë‹¤.", 10)
            self.add_memory('event', f"ë‚˜ì˜ ì„±ê²© ë° ì„¤ì •: '{self.persona_description}'", 10)
            # self.add_memory('thought', f"[ëª©í‘œ] ë‚˜ì˜ í˜„ì¬ ëª©í‘œëŠ” '{self.current_goal}'ì´ë‹¤.", 9)
        

        # ì ìˆ˜ ê°€ì¤‘ì¹˜
        self.score_weights = np.array(SCORE_WEIGHTS)
        self.recency_decay = RECENCY_DECAY
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ JSON ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _load_memory_rooms(self):
        """short_term.json, long_term.jsonì„ ì½ì–´ ë©”ëª¨ë¦¬ ê°ì²´ë¡œ ë³µêµ¬"""
        for path, target in [
            (self.short_term_path, self.short_term_memory_room),
            (self.long_term_path,  self.long_term_memory_room)
        ]:
            if not os.path.exists(path):
                continue
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)

            for item in data:
                mem = Memory(
                    memory_type=item["type"],
                    description=item["desc"],
                    importance=item["imp"],
                    embedding=self.llm_utils.get_embedding(item["desc"]),
                    keywords=self._extract_keywords(item["desc"])
                )
                mem.timestamp = datetime.datetime.fromisoformat(item["ts"])
                target.append(mem)

                # ğŸ”¸ 1) seq_event / seq_thoughtì—ë„ ë„£ê¸°
                if mem.type == 'event':
                    self.seq_event.append(mem)
                else:
                    self.seq_thought.append(mem)

                # ğŸ”¸ 2) í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ë³µêµ¬
                for kw in mem.keywords:
                    (self.kw_to_event if mem.type == 'event' else self.kw_to_thought)[kw].append(mem)
                    self.kw_strength[kw] += mem.importance


    def set_persona_description(self, persona_desc: str):
        """NPCì˜ í˜ë¥´ì†Œë‚˜ ì„¤ëª…ì„ ì„¤ì •"""
        self.persona_description = persona_desc

    def _extract_keywords(self, description: str) -> set[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        prompt = (
            "ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 5ê°œ ì´í•˜ë¡œ ì¶”ì¶œí•´ì¤˜. "
            "ë¬¸ì¥ì´ í•¨ì˜í•˜ëŠ” 'ê°œë…'ë„ í¬í•¨í•´ì¤˜(ì˜ˆ: \"ë‚˜ëŠ” ê²½ìš°ì•¼\" -> ì´ë¦„, ìê¸°ì†Œê°œ). "
            f"ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ëª…ì‚¬ í˜•íƒœë¡œ ì¶œë ¥í•´ì¤˜.\n\në¬¸ì¥: \"{description}\"\ní‚¤ì›Œë“œ:"
        )
        response = self.llm_utils.get_llm_response(prompt, temperature=0.1, max_tokens=50)
        return {kw.strip() for kw in response.split(',') if kw.strip()}

    def add_memory(self, memory_type: str, description: str, importance: int = -1,
                   evidence_ids: list[str] = None):
        """ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ë¥¼ ì¶”ê°€"""
        if importance == -1:
            # ì¤‘ìš”ë„ ê³„ì‚° ì‹œ memory_typeì„ í•¨ê»˜ ì „ë‹¬
            importance = self._calculate_importance(description, memory_type)

        embedding = self.llm_utils.get_embedding(description)
        keywords = self._extract_keywords(description)
        new_memory = Memory(memory_type, description, importance, embedding, keywords, evidence_ids)

        # ë©”ëª¨ë¦¬ ì €ì¥
        if memory_type == 'event':
            self.seq_event.append(new_memory)
        else:
            self.seq_thought.append(new_memory)

        # í‚¤ì›Œë“œ ì¸ë±ì‹±
        for kw in keywords:
            if memory_type == 'event':
                self.kw_to_event[kw].append(new_memory)
            else:
                self.kw_to_thought[kw].append(new_memory)
            self.kw_strength[kw] += importance

        # ë‹¨ê¸° ë©”ëª¨ë¦¬ ë£¸ ì²˜ë¦¬
        if memory_type == 'event':
            self.short_term_memory_room.append(new_memory)

            if len(self.short_term_memory_room) >= SUMMARY_WINDOW:
                self._summarize_short_term()
                self.short_term_memory_room.clear()

        self._save_memory_rooms()
        print(f"DEBUG (Add Memory): {new_memory}")

    def _calculate_importance(self, description: str, memory_type: str) -> int:
        """
        ê¸°ì–µì˜ ì¢…ë¥˜(memory_type)ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        (ë…¼ë¬¸ í”„ë¡¬í”„íŠ¸ ì°¸ì¡°: poignancy_event_v1.txt, poignancy_thought_v1.txt, poignancy_chat_v1.txt)
        """
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°
        prompt_template = """
          ë‹¤ìŒì€ '{name}'ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ì…ë‹ˆë‹¤.
          {persona_description}

          1ì ì—ì„œ 10ì ê¹Œì§€ì˜ ì²™ë„ì—ì„œ, ë‹¤ìŒ {memory_category}ì˜ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•´ ì£¼ì„¸ìš”.
          1ì ì€ '{mundane_example}'ì²˜ëŸ¼ ì§€ê·¹íˆ í‰ë²”í•œ ê²ƒì´ë©°, 10ì ì€ '{poignant_example}'ì²˜ëŸ¼ ë§¤ìš° ì¤‘ëŒ€í•œ ê²ƒì…ë‹ˆë‹¤.

          {memory_category_label}: {description}
          ì ìˆ˜ (1ì—ì„œ 10 ì‚¬ì´ì˜ ìˆ«ì í•˜ë‚˜ë§Œ ë°˜í™˜):
          """

        # ê¸°ì–µ ì¢…ë¥˜ë³„ ì„¤ì •ê°’
        if memory_type == 'event':
            settings = {
                "memory_category": "ì‚¬ê±´",
                "memory_category_label": "ì‚¬ê±´",
                "mundane_example": "ì´ë¥¼ ë‹¦ê±°ë‚˜ ì¹¨ëŒ€ë¥¼ ì •ë¦¬í•˜ëŠ” ê²ƒ",
                "poignant_example": "ì´ë³„ì´ë‚˜ ëŒ€í•™ í•©ê²©"
            }
        elif memory_type == 'thought':
            settings = {
                "memory_category": "ìƒê°",
                "memory_category_label": "ìƒê°",
                "mundane_example": "ì„¤ê±°ì§€ë¥¼ í•´ì•¼ í•œë‹¤",
                "poignant_example": "êµìˆ˜ê°€ ë˜ê³  ì‹¶ë‹¤"
            }
        # 'chat'ì´ë‚˜ 'summary' ë“± ë‹¤ë¥¸ íƒ€ì…ë„ 'event'ì™€ ìœ ì‚¬í•˜ê²Œ ì²˜ë¦¬
        else:
            settings = {
                "memory_category": "ëŒ€í™” ë‚´ìš©",
                "memory_category_label": "ëŒ€í™”",
                "mundane_example": "ì¼ìƒì ì¸ ì•„ì¹¨ ì¸ì‚¬",
                "poignant_example": "ì´ë³„ì— ëŒ€í•œ ëŒ€í™”ë‚˜ ì‹¸ì›€"
            }

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = prompt_template.format(
            name=self.name,
            persona_description=self.persona_description,
            memory_category=settings["memory_category"],
            mundane_example=settings["mundane_example"],
            poignant_example=settings["poignant_example"],
            memory_category_label=settings["memory_category_label"],
            description=description
        )

        try:
            response = self.llm_utils.get_llm_response(prompt, temperature=0.0, max_tokens=3)
            importance = int(response)
            return max(1, min(10, importance))
        except (ValueError, TypeError):
            # LLMì´ ìˆ«ìê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë‹µë³€ì„ í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
            return 5

    def _summarize_short_term(self):
        """ë‹¨ê¸° ë©”ëª¨ë¦¬ë¥¼ ìš”ì•½í•˜ì—¬ ì¥ê¸° ë©”ëª¨ë¦¬ë¡œ ì´ê´€"""
        joined = "\n".join([m.description for m in self.short_term_memory_room])
        prompt = f"ë‹¤ìŒ ì‚¬ê±´ë“¤ì˜ í•µì‹¬ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n{joined}\n\n[ìš”ì•½]"
        summary_sentence = self.llm_utils.get_llm_response(prompt, temperature=0.3, max_tokens=60)

        embedding = self.llm_utils.get_embedding(summary_sentence)
        keywords = self._extract_keywords(summary_sentence)
        summary_mem = Memory("summary", summary_sentence, 8, embedding, keywords)
        self.long_term_memory_room.append(summary_mem)

    def _normalize_scores(self, scores: dict) -> dict:
        """ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ë¥¼ 0ê³¼ 1 ì‚¬ì´ë¡œ ì •ê·œí™”í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜"""
        if not scores:
            return {}

        min_val = min(scores.values())
        max_val = max(scores.values())
        range_val = max_val - min_val

        if range_val == 0:
            return {k: 0.5 for k in scores}  # ëª¨ë“  ê°’ì´ ê°™ìœ¼ë©´ ì¤‘ê°„ê°’ì¸ 0.5ë¡œ ì„¤ì •

        normalized_scores = {
            key: (val - min_val) / range_val
            for key, val in scores.items()
        }
        return normalized_scores

    def retrieve_memories(self, query: str, top_k: int = 5) -> list[Memory]:
        """
        ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰ (ë…¼ë¬¸ ë¡œì§ ì ìš© ë²„ì „)
        ìµœê·¼ì„±(Recency), ì¤‘ìš”ë„(Importance), ê´€ë ¨ì„±(Relevance)ì„ ì¢…í•©í•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
        """
        print(f"\nDEBUG (Retrieve): \"{query}\"ì™€ ê´€ë ¨ëœ ê¸°ì–µ ê²€ìƒ‰ ì¤‘...")

        # --- 1. ëª¨ë“  ê¸°ì–µ ë…¸ë“œ ìˆ˜ì§‘ ---
        all_memories = (
                self.seq_event + self.seq_thought +
                list(self.short_term_memory_room) + self.long_term_memory_room
        )
        # ì¤‘ë³µ ì œê±° ë° IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
        mem_map = {mem.id: mem for mem in all_memories}
        if not mem_map:
            return []

        # --- 2. ì„¸ ê°€ì§€ í•µì‹¬ ì ìˆ˜ ê³„ì‚° ---
        query_embedding = self.llm_utils.get_embedding(query)

        recency_scores = {}
        importance_scores = {}
        relevance_scores = {}

        now = datetime.datetime.now()
        for mem_id, mem in mem_map.items():
            # ìµœê·¼ì„± ì ìˆ˜ ê³„ì‚°
            hours_since_access = (now - mem.last_accessed).total_seconds() / 3600
            recency_scores[mem_id] = pow(self.recency_decay, hours_since_access)

            # ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
            importance_scores[mem_id] = mem.importance

            # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
            relevance_scores[mem_id] = self._cosine_similarity(query_embedding, mem.embedding)

        # --- 3. ì ìˆ˜ ì •ê·œí™” ---
        # ê° ì ìˆ˜ ì…‹ì„ 0ê³¼ 1 ì‚¬ì´ë¡œ ì •ê·œí™”í•˜ì—¬ ê³µí‰í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ë§Œë“­ë‹ˆë‹¤.
        norm_recency = self._normalize_scores(recency_scores)
        norm_importance = self._normalize_scores(importance_scores)
        norm_relevance = self._normalize_scores(relevance_scores)

        # --- 4. ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í•©ì‚°) ---
        # ê°€ì¤‘ì¹˜: [ìµœê·¼ì„±, ê´€ë ¨ì„±, ì¤‘ìš”ë„]. ë…¼ë¬¸ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.
        # ì´ ê°’ë“¤ì„ ì¡°ì ˆí•˜ì—¬ NPCì˜ ê¸°ì–µ ì„±í–¥ì„ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        weights = [0.5, 3.0, 2.0]

        final_scores = {}
        for mem_id in mem_map:
            final_scores[mem_id] = (
                    weights[0] * norm_recency.get(mem_id, 0) +
                    weights[1] * norm_relevance.get(mem_id, 0) +
                    weights[2] * norm_importance.get(mem_id, 0)
            )

        # --- 5. ìµœìƒìœ„ ê¸°ì–µ ì„ íƒ ë° ë°˜í™˜ ---
        # ìµœì¢… ì ìˆ˜ì— ë”°ë¼ ë©”ëª¨ë¦¬ IDë¥¼ ì •ë ¬
        sorted_mems = sorted(final_scores.items(), key=lambda item: item[1], reverse=True)

        # ìƒìœ„ top_kê°œì˜ ë©”ëª¨ë¦¬ ê°ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        retrieved_ids = [mem_id for mem_id, score in sorted_mems[:top_k]]
        retrieved = [mem_map[mem_id] for mem_id in retrieved_ids]

        # ì¸ì¶œëœ ê¸°ì–µì˜ ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ì„ ê°±ì‹ 
        for mem in retrieved:
            mem.last_accessed = datetime.datetime.now()

        print(f"DEBUG (Retrieve): ìµœì¢… ìƒìœ„ ê¸°ì–µ {len(retrieved)}ê°œ:\n{[m.description for m in retrieved]}\n")
        return retrieved

    def retrieve_knowledge(self, query: str, top_k: int = 3) -> list[str]:
        """ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰"""
        print(f"DEBUG (Knowledge Retrieve): '{query}' ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ ì¤‘...")
        if not self.knowledge_base:
            return []

        lookup_prompt = (
            "ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ë‚´ê°€ ë‚˜ì˜ 'ì§€ì‹ ë² ì´ìŠ¤'ì—ì„œ ê·¸ ì˜ë¯¸ë¥¼ ì°¾ì•„ë´ì•¼ í•  ì¤‘ìš”í•œ ê³ ìœ ëª…ì‚¬ë‚˜ í•µì‹¬ ê°œë…ì€ ë¬´ì—‡ì´ì•¼? "
            "ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ì–´ë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì•Œë ¤ì¤˜.\n\n"
            f"ë¬¸ì¥: \"{query}\"\n\nì°¾ì•„ë´ì•¼ í•  ë‹¨ì–´:"
        )
        response = self.llm_utils.get_llm_response(lookup_prompt, temperature=0.0, max_tokens=50)
        query_keywords = {kw.strip() for kw in response.split(',') if kw.strip()}

        print(f"DEBUG (Knowledge Retrieve): LLMì´ ì„ ë³„í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ -> {query_keywords}")
        if not query_keywords:
            return []

        # í‚¤ì›Œë“œì™€ ì§€ì‹ ë² ì´ìŠ¤ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        candidate = []
        for kw in query_keywords:
            kw_emb = self.llm_utils.get_embedding(kw)
            for know in self.knowledge_base.values():
                sim = self._cosine_similarity(kw_emb, know.embedding)
                candidate.append((sim, know))

        candidate.sort(key=lambda x: x[0], reverse=True)
        seen, results = set(), []
        for _, know in candidate:
            if know.concept not in seen:
                results.append(f"- {know.concept}: {know.description}")
                seen.add(know.concept)
                if len(results) >= top_k:
                    break

        print(f"DEBUG (Knowledge Retrieve): ê²€ìƒ‰ëœ ì§€ì‹ -> {results}")
        return results

    def learn_from_interaction(self, interaction: str) -> dict:
        """ìƒí˜¸ì‘ìš©ìœ¼ë¡œë¶€í„° ìƒˆë¡œìš´ ì§€ì‹ í•™ìŠµ (ìƒˆë¡œ í•™ìŠµí•œ ì§€ì‹ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)"""
        print(f"DEBUG (Knowledge): ìƒˆë¡œìš´ ì§€ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤...")
        prompt = f"""
        ë‹¤ìŒì€ '{self.name}'ì™€(ê³¼) í”Œë ˆì´ì–´ ê°„ì˜ ëŒ€í™”ì™€, '{self.name}'ê°€ ì´ë¯¸ ì•Œê³  ìˆëŠ” ì§€ì‹ ëª©ë¡ì…ë‹ˆë‹¤.

        [ëŒ€í™” ë‚´ìš©]
        {interaction}

        [ì´ë¯¸ ì•Œê³  ìˆëŠ” ì§€ì‹]
        {list(self.knowledge_base.keys())}

        [ì§€ì‹œ]
        ìœ„ ëŒ€í™”ì—ì„œ '{self.name}'ê°€ 'ìƒˆë¡­ê²Œ' ì•Œê²Œ ëœ ì¤‘ìš”í•œ ì‚¬ì‹¤ì„ JSON ê°ì²´ë¡œ ì¶”ì¶œí•´ì¤˜.
        - **ê³ ìœ ëª…ì‚¬:** ì‚¬ëŒ ì´ë¦„, ì¥ì†Œ, íŠ¹ì • ê³¼ëª©ëª… ë“±.
        - **ê´€ê³„ì  ì˜ë¯¸:** ì¼ë°˜ì ì¸ ë‹¨ì–´ì§€ë§Œ ì´ ëŒ€í™”ì˜ ë§¥ë½ì—ì„œ íŠ¹ë³„í•œ ì˜ë¯¸ë¥¼ ê°–ê²Œ ëœ ê²½ìš°.
        ì„¤ëª…ì€ ë°˜ë“œì‹œ í”Œë ˆì´ì–´ì™€ì˜ ê´€ê³„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

        - **ì¢‹ì€ ì˜ˆì‹œ 1 (ê³ ìœ ëª…ì‚¬):** í”Œë ˆì´ì–´ê°€ "ì €ëŠ” ì»´ê³µì„ ì „ê³µí•˜ëŠ” ê²½ìš°ì…ë‹ˆë‹¤" ë¼ê³  ë§í–ˆë‹¤ë©´,
          ê²°ê³¼ëŠ” {{"ê²½ìš°": "í”Œë ˆì´ì–´ì˜ ì´ë¦„", "ì»´ê³µ": "í”Œë ˆì´ì–´ê°€ ì „ê³µí•˜ê³  ìˆëŠ” í•™ê³¼"}} ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        - **ì¢‹ì€ ì˜ˆì‹œ 2 (ê´€ê³„ì  ì˜ë¯¸):** í”Œë ˆì´ì–´ê°€ "ì œ ì¡¸ì—… ì‘í’ˆì€ ì €ì˜ 'í°ê³ ë˜'ì˜ˆìš”" ë¼ê³  ë§í–ˆë‹¤ë©´,
          ê²°ê³¼ëŠ” {{"í°ê³ ë˜": "í”Œë ˆì´ì–´ê°€ ìì‹ ì˜ ì–´ë µê³  ì¤‘ìš”í•œ ì¡¸ì—… ì‘í’ˆì„ ë¹„ìœ ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë§"}} ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        - **ë‚˜ìœ ì˜ˆì‹œ (ì¼ë°˜ ì‚¬ì‹¤):** í”Œë ˆì´ì–´ê°€ "í•˜ëŠ˜ì€ íŒŒë—ë‹¤" ë¼ê³  ë§í–ˆë‹¤ë©´, ê²°ê³¼ëŠ” {{}} ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

        ìƒˆë¡œ ì•Œê²Œ ëœ ì‚¬ì‹¤ì´ ì—†ë‹¤ë©´, ë¹ˆ JSON ê°ì²´ {{}}ë¥¼ ë°˜í™˜í•´.
        ë°˜ë“œì‹œ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ê³ .

        [JSON ì¶œë ¥]
        """
        response_str = self.llm_utils.get_llm_response(prompt, temperature=0.1, max_tokens=500, is_json=True)

        try:
            new_knowledge = json.loads(response_str)
            if new_knowledge:
                for concept, desc in new_knowledge.items():
                    if concept not in self.knowledge_base:
                        emb = self.llm_utils.get_embedding(concept)
                        self.knowledge_base[concept] = Knowledge(concept, desc, emb)
                        print(f"DEBUG (Knowledge): ìƒˆë¡œìš´ ì§€ì‹ ì¶”ê°€! -> {self.knowledge_base[concept]}")
                        print(f'thought', f"[ì§€ì‹ ìŠµë“] '{concept}'ì€(ëŠ”) '{desc}'ë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆë‹¤.")

        except json.JSONDecodeError:
            print(f"DEBUG (Knowledge): ì§€ì‹ ì¶”ì¶œ ì‹¤íŒ¨. ì‘ë‹µ: {response_str}")

    def _cosine_similarity(self, v1, v2):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        v1, v2 = np.array(v1), np.array(v2)
        norm1, norm2 = np.linalg.norm(v1), np.linalg.norm(v2)
        return np.dot(v1, v2) / (norm1 * norm2) if norm1 != 0 and norm2 != 0 else 0.0

    def _save_memory_rooms(self):
        """ë©”ëª¨ë¦¬ ë£¸ì„ íŒŒì¼ë¡œ ì €ì¥"""

        def _to_dict(mem: Memory):
            return {
                "type": mem.type,
                "desc": mem.description,
                "imp": mem.importance,
                "ts": mem.timestamp.isoformat()
            }

        with open(self.short_term_path, "w", encoding="utf-8") as f:
            json.dump([_to_dict(m) for m in self.short_term_memory_room], f, ensure_ascii=False, indent=2)

        with open(self.long_term_path, "w", encoding="utf-8") as f:
            json.dump([_to_dict(m) for m in self.long_term_memory_room], f, ensure_ascii=False, indent=2)